---
title: "Assignment5"
author: "Manish Kumar"
date: "Feb 8, 2023"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

### Analysis of Moody’s Bond Yields
#### This assignment helps understanding regression with stationary residuals and cointegration
#### Consider the monthly yields of Moody’s AAA and BAA bonds from. The data are in the file `MYieldsData.csv`. Analyze possible types of relationships between the two yield variables using regression model with stationary residuals and cointegration.
#### What is a valid model for predicting the data?

#### Plots
```{r}
library(forecast)
library(tseries)
library(plotrix)

x = read.csv(file=paste("MYieldsData.csv", sep="/"), header=T)
n = nrow(x)

# We'll select a more recent and shorter period of last 900 observations of the data
nb = max(n-900, 1)
aaa = x[nb:n, 2]  ### AAA Yield
baa = x[nb:n, 3]  ### BAA Yield

plot(aaa, col ="blue", type="l", ylab="Monthly Yields", lwd=2,
     main="Moody's AAA and BAA Bond monthly yields")
lines(baa, col="orange", lwd=2)
legend("topright", c("AAA","BAA"), lwd=c(2,2),col = c("blue","orange"), bty="n")
```


```{r}
# Scatter Plot of aaa and baa to observe the level of correlation between the variables
aaa = as.vector(aaa)
baa = as.vector(baa)
plot(aaa, baa, col="blue")

```

Visually, there looks to be a good correlation between them. We'll build a linear fit and quantify the relationship next

#### Regression Model

```{r}
linreg = lm(baa~aaa)
summary(linreg)
```

```{r}
# Explore the residuals
plot(linreg$residuals,type="l",col ="blue")
acf(linreg$residuals)
Box.test(linreg$residuals, lag=12, type="Ljung")
```

The sample ACF of residuals is highly significant and there's no sharp decay, showing that the process is not stationary.
There is a pattern of a unit-root non-stationary time series, in other words two bond yields are not co-integrated.

This behavior of residuals leads to the consideration of differencing the series of interest rates.

```{r}
aaa.diff = diff(aaa)
baa.diff = diff(baa)
plot(aaa.diff, baa.diff, main="Scatter plot of Differences", col = "blue")
```

There's still some correlation. Fitting the linear regression to this new data with no intercept.

```{r}
clinreg = lm(baa.diff~aaa.diff-1)
summary(clinreg)
```

Repeat the analysis we did for residuals for previous model

```{r}
cresiduals = clinreg$residuals
plot(cresiduals,type ="l",col = "blue")
acf(cresiduals,main = "ACF of residuals",col ="blue",lty=1 ,lwd = 4)
Box.test(cresiduals,lag=10,type='Ljung')
```


The residuals this time are more stationary. However, Box-Ljung test shows that serial correlation is still present.
ACF plots show significant correlation at multiple lags as well.

Use `auto.arima` function to find the best `arima` model with lowest AIC/BIC.

```{r}
ma1 = auto.arima(cresiduals, seasonal=T)
summary(ma1, which="all")
```

`auto.arima` function suggests `MA(1)` model

```{r}
tsdiag(ma1, gof=12)
```

Estimated a model for two bond yields series:

$x_{t,baa}=x_{t-1,baa}+\beta_{2}(x_{t,aaa}-x_{t-1,aaa})+\epsilon_{t},t=2,...,T$

$\epsilon_{t}=a_{t}-\theta*a_{t-1},t=2,…,T$

Now, building a forecast model.

First, find forecast for$\epsilon_{t},t=2,…,T$ using `MA(1)` model:

$\epsilon_{t}=-\theta*a_{t}=-\theta*ResidualsMA(1)_{t-1}$

Note that `arma()` uses MA coefficients with opposite signs as the book.

Forecast the BAA yields using the equation above and Plot the BAA yields and the forecast
```{r,warning=FALSE}
theta1 = ma1$coef[1]
a_t = theta1 * residuals(ma1)

x_1 = baa[-length(baa)]
forec = x_1 + clinreg$coefficients * aaa.diff + a_t
matplot(cbind(baa[-1], forec), type="l", col=c("blue", "orange"),
        main="BAA Yields and Forecast", ylab="BAA yield and Forecast")
legend("topright", c("BAA Yields","Forecasts"), lwd=2,col = c("blue","orange"), bty="n")
```

 Check the scatter plot of BAA Yields forecast differences versus differences of AAA Yields.

```{r}
difforec = diff(forec)
cr = cbind(difforec, aaa.diff[-1])
plot(cr[,1], cr[,2], col="blue",
     main="Differences of Forecasted BAA Yields vs Differences of AAA Yields",
     xlab="Difference of Forecasts of BAA Yields",
     ylab="Differences of AAA Yields")

```

Figure shows that regression model with ARIMA residuals preserved the “short term” dependence of yields increments.

#### Co-integration

Fit co-integration model

```{r}
library(urca)

data = cbind(aaa, baa)
cajo = ca.jo(data, ecdet = "none", type="eigen", K=2, spec="longrun")
summary(cajo)

```

Residuals and their ACF’s and PACF’s for aaa and baa yields, respectively

```{r}
plotres(cajo)
```

Check statistics and critical values of the test for cointegration order

```{r, fig.width = 10, fig.height = 9}
par(mfcol=c(2,1))
barplot(cajo@cval[1,], main = "Johansen test h<=1",col = "red")
abline(h=cajo@teststat[1], col="blue")
legend("topleft", c("critical values","test statistics"), lwd=2,col = c("red","blue"), bty="n")

barplot(cajo@cval[2,],main = "Johansen test h=0",col = "red",ylim=c(0,22))
abline(h=cajo@teststat[2], col="blue")
legend(0.2,18, c("critical values","test statistics"), lwd=2,col = c("red","blue"), bty="n")

```

The variable `cajo@cval` returns the critical values of the null hypothesis indicated in the output table of the variable and on the titles of the barplots.
For all levels of 10%, 5%, 1% the statistic is below the critical values. So, `H0: r<=1` cannot be rejected.

The second chart shows the same variables, but for `H0: r=0`. For this null hypothesis the test statistic is above the critical values for 10%, 5% and 1%. So, with levels of 1% or more `H0: r=0` is rejected.

*Conclusion: the cointegrating order equals 1.*

By definition of cointegration with order r=1 process $z_{t,1}=a^T_{1}*x_{t}$ must be stationary (`I(0)`)

```{r}
# Cointegration vector a1
a_1 = cajo@V[,1]

z_t1 = data %*% a_1
matplot(z_t1, type ="l", main = "z(1,t)=a1'x(t)", col = "blue")
```

Estimate autoregression model for process `zt1` and find the order chosen

```{r, warning=FALSE}
zar = ar(z_t1,  aic = TRUE, method = "yule-walker")
zar$order
adf.test(z_t1, k=zar$order, alternative="stationary") 
```

The order of the AR process is chosen by R using the Akaike Information Criterion (AIC)

Check the roots of characteristic equation

```{r}
par(mfrow = c(1, 1), cex = 0.9)
polyPar = c(1,-zar$ar)
r18 = polyroot(polyPar)
Mod(r18)
r18Re = Re(r18)
r18Im = Im(r18)
plot(r18Re,r18Im,xlim=c(min(r18Re),max(r18Re)),asp=1,ylim=c(min(r18Im),max(r18Im)))
draw.circle(0,0,radius=1)
```

The ADF test gives us a significant p-value and we can reject the null hypothesis that there is at least one unit root.

The plot of the characteristic equation roots shows that all the roots are larger than the unit circle.

The process is stationary

Since cointegration order equals 1, vector `a2` is not a cointegration vector and the process $z_{t,2}=a^T_{2}*x_{t}$ should not stationary.

```{r}
a_2 = cajo@V[,2]
z_t2 = data %*% a_2
matplot(z_t2,type ="l", main = "z(2,t)=a2'x(t)", col = "blue")
```

The plot does not look stationary.

ADF test for `z_t2`
```{r}
zar2 = ar(z_t2, aic = TRUE,method = "yule-walker")
zar2$order
adf.test(z_t2,k=zar2$order,alternative="stationary") 

```
The ADF test gives us a very insignificant p-value and we cannot reject the null hypothesis that there is at least one unit root. ADF test verifies that z_t2 is not stationary and a2 is not a cointegration vector.

*Prediction using Cointegration model*

$\Delta X_{t} = \Gamma *\Delta X_{t-1} + \Pi_{1} * X_{t-2} + \mu + \epsilon_{t}$

```{r}
mu = cajo@GAMMA[,1]
```

Matrix of coefficients $\Pi_1$ (slot `PI` of class `ca.jo`)
```{r}
PI = cajo@PI
```

Matrix of coefficients $\Gamma$ (slot `GAMMA` of class `ca.jo`)
```{r}
Gamma = cajo@GAMMA[,2:3]
```

In order to construct forecasts we also need matrix $\Delta X_{t-1}$ and matrix $X_{t-2}$ ,t=3,…,T

Matrix $\Delta X_{t-1}$,t=3,…,T (slot `Z0` of class `ca.jo`):
```{r}
dX_1 = cajo@Z0
```

Matrix $X_{t-2}$,t=3,…,T (slot `ZK` of class `ca.jo`):
```{r}
X_2 = cajo@ZK
```

Denote the forecast itself as $\Delta \hat{X}_t(1)$
Conditional expectation of the forecast
$E[\Delta \hat {X}_t(1)|t]=\Gamma \Delta X_{t}+\Pi_1 X_{t-1}+\mu,~t = 3,\ldots,T$

```{r}
deltaX_t_1 = Gamma %*% t(dX_1) + PI %*%t(X_2) 
deltaX_t_1 = apply(deltaX_t_1,2,"+",mu)
```

The forecasts for rates are $E[\hat{X}_t(1)|t]=E[X_t+\Delta \hat {X}_t(1)|t]=  X_t+E[\Delta \hat{X}_t(1)|t]= X_t+\Gamma \Delta X_{t}+\Pi X_{t-1}+\mu,~t = 3,\ldots,T$
```{r}
nrowsdata = dim(data)[1]
data_t_2 = data[3:nrowsdata,]
deltaX_t_1 = t(deltaX_t_1)
forecX = data_t_2+deltaX_t_1
```
Plot predictions of the aaa bond yields

```{r}
fraaa = cbind(aaa[3:length(aaa)],forecX[,1])
matplot(fraaa,col =c("blue","orange"),type="l",lwd=c(2,2),
        main = "AAA bond yields and prediction")
legend("topright", c("AAA bond yields","Prediction"), lwd=c(2,2),
       col = c("blue","orange"), bty="n")

```

Plot predictions of the baa bond yields

```{r}
frbaa = cbind(baa[3:length(baa)],forecX[,2])
matplot(frbaa,col =c("blue","orange"),type="l",lwd=c(2,2),
        main = "BAA bond yields and prediction")
legend("topright", c("BAA bond yields","Prediction"), lwd=c(2,2),
       col = c("blue","orange"), bty="n")

```

Figures show that cointegration model preserved long term dependence of both AAA and BAA Bond Yields.

Difference the forecasts and plot them.
```{r}
dfraaa = diff(fraaa)
dfrbaa = diff(frbaa)
plot(dfraaa,dfrbaa,col ="blue",
     main = "Scatter plot for change of prediction for AAA and BAA Yields",
     xlab="Differenced Forecasts of AAA Yields",ylab="Differenced Forecasts of BAA Yields")


```

Figure shows that cointegration model also captured short term dependence of Yields differences.

Check errors of prediction by the cointegration model.
```{r}
cerrorA = aaa[3:length(aaa)]-forecX[,1]
cerrorB = baa[3:length(baa)]-forecX[,2]
matplot(cerrorA,main = "Error of Prediction of AAA Bond Yield",type = "l")
matplot(cerrorB,main = "Error of Prediction of BAA Bond Yield",type = "l")
```

```{r}
plot(cerrorA,cerrorB,col ="blue",
     main = "Scatter plot for errors of prediction for AAA and BAA Bond Yields")
cor(cbind(cerrorA,cerrorB))
```

The standard errors for both bonds using cointegration model are highly correlated. They tend to increase together.

#### Model Comparison

Compare the errors of the regression model with stationary residuals for BAA Bond to the errors of cointegration model for the BAA Bond.

```{r}
linregerror = baa[-1]-forec
errors = cbind(linregerror[-1],cerrorB)
matplot(errors,type ="l",col = c("orange","blue"),lwd=2,
        main = "BAA Yield Errors for Regression and Cointegration Model")
legend("topleft", c("regression errors","cointegration errors"), lwd=2,
       col = c("orange","blue"), bty="n")
```

```{r}
paste("The total variance for Regression Model Error is ", var(errors[,1]))
paste("The total variance for Cointegration Model Error is ", var(errors[,2]))
```

The variance level of cointegration errors is higher than the regression model errors.

Check for a relationship between the errors of the two models
```{r}
plot(errors[,1],errors[,2],col = "blue", 
     main = "Scatter Plot of Regression model Errors vs Cointegration errors",
     xlab="Regression Model Errors", ylab="Cointegration Model Errors")
cor(errors)
```

There is a small negative correlation between the errors of the two models.

Based on the prediction plots and error plots, both seem to be valid models for predicting the last 900 observations of the data. However the regression model did a better job of forecasting based on comparing the variance of the errors of both models.


